{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1199a4a"
      },
      "source": [
        "Let's break down the code step-by-step:\n",
        "\n",
        "### 1. Setup & Data Loading\n",
        "This section initializes the necessary libraries and loads the primary data. It prepares the environment for the analysis and sets up the base dataframes we'll be working with.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00c89d7e"
      },
      "source": [
        "*   **Import Libraries**: We import `pandas` for data manipulation, `numpy` for numerical operations, `yfinance` to download stock data, `nltk` for natural language processing (specifically sentiment analysis), `sklearn` for machine learning utilities (model selection and metrics), `pandas_ta` for technical indicators, and `xgboost` for our gradient boosting model.\n",
        "*   **NLTK VADER Lexicon**: `nltk.download('vader_lexicon')` ensures the necessary lexicon for sentiment analysis is available, and `SentimentIntensityAnalyzer()` is initialized.\n",
        "*   **Download S&P 500 Data**: `yf.download(\"^GSPC\", start=\"2020-01-01\", end=\"2024-01-01\")` fetches historical stock data for the S&P 500 index (`^GSPC`) and stores it in `stock_df`.\n",
        "*   **Flatten MultiIndex Columns**: Yfinance sometimes returns a DataFrame with MultiIndex columns. The code checks for this and flattens them to a single level (e.g., from `('Close', '^GSPC')` to `Close`).\n",
        "*   **Create Dummy News Data**: Since we don't have a real news CSV, a `news_df` DataFrame is created with dummy headlines. In a real scenario, you would load a CSV file containing actual financial news headlines here. The headlines pattern is repeated to match the number of stock dates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b0f4b0a"
      },
      "source": [
        "### 2. Sentiment Analysis (NLP)\n",
        "This part of the code analyzes the sentiment of the news headlines to extract a numerical score representing positivity or negativity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35bb8298"
      },
      "source": [
        "*   **`get_sentiment(text)` function**: This function takes a piece of text (a headline) and uses `sia.polarity_scores(text)['compound']` to calculate a compound sentiment score. This score ranges from -1 (most negative) to +1 (most positive).\n",
        "*   **Apply to News Data**: `news_df['Sentiment_Score'] = news_df['Headline'].apply(get_sentiment)` applies this function to every headline in our `news_df` to generate a new column named `Sentiment_Score`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ceda5c7"
      },
      "source": [
        "### 3. Add Technical Indicators\n",
        "Here, we calculate various technical indicators from the stock's price data. These indicators are widely used in financial analysis to provide insights into market trends, momentum, and potential buy/sell signals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ea6fb12"
      },
      "source": [
        "*   **Simple Moving Averages (SMA)**: `stock_df['Close'].rolling(window=X).mean()` calculates the average closing price over `X` periods (5, 10, and 20 days), helping to smooth out price data and identify trends.\n",
        "*   **Exponential Moving Averages (EMA)**: `stock_df['Close'].ewm(span=X, adjust=False).mean()` calculates an EMA for 5, 10, and 20 days. EMAs give more weight to recent prices, making them more responsive to new information.\n",
        "*   **Relative Strength Index (RSI)**: `ta.rsi(stock_df['Close'], length=14)` computes the 14-period RSI, a momentum oscillator that measures the speed and change of price movements, indicating overbought or oversold conditions.\n",
        "*   **Moving Average Convergence Divergence (MACD)**: `ta.macd(stock_df['Close'], fast=12, slow=26, signal=9)` calculates the MACD line, signal line, and histogram. It's a trend-following momentum indicator that shows the relationship between two moving averages of a security’s price.\n",
        "*   **Handle NaN Values**: Technical indicators often produce `NaN` (Not a Number) values at the beginning of the series because they require historical data. `stock_df.ffill()` forward-fills these `NaN`s, and `stock_df.dropna()` removes any remaining `NaN`s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e9c5ef1"
      },
      "source": [
        "### 4. Data Alignment (Feature Engineering)\n",
        "This section prepares the data for machine learning by defining the target variable and merging the sentiment and technical indicators."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b35bca53"
      },
      "source": [
        "*   **Calculate `Price_Diff` and `Target`**: `stock_df['Price_Diff'] = stock_df['Close'].diff()` calculates the difference in closing price from the previous day. `stock_df['Target'] = (stock_df['Price_Diff'].shift(-1) > 0).astype(int)` creates our target variable: `1` if the stock price increased *the next day* (shifted by -1), and `0` otherwise. This is crucial for predicting future movement.\n",
        "*   **Merge DataFrames**: `final_df = pd.merge(stock_df, news_df, on='Date')` combines the `stock_df` (now with technical indicators and target) and `news_df` (with sentiment scores) into a single `final_df` based on the common 'Date' column.\n",
        "*   **Drop Remaining NaNs**: `final_df = final_df.dropna()` cleans up any `NaN` values that might still exist after merging or due to the shifting of the target variable (the very last day will have a `NaN` target as there's no 'next day' to predict)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be63a821"
      },
      "source": [
        "### 5. Model Training with XGBoost\n",
        "This is where we define our machine learning model, train it, and evaluate its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83812b1c"
      },
      "source": [
        "*   **Define Features (X) and Target (y)**: `X` is created using the sentiment score and all the financial features (`Open`, `High`, `Low`, `Volume`, SMA, EMA, RSI, MACD components). `y` is our `Target` variable (whether the stock went up or down).\n",
        "*   **Split Data**: `train_test_split(X, y, test_size=0.2, random_state=42)` divides the data into training (80%) and testing (20%) sets. This allows us to train the model on one portion of the data and evaluate its performance on unseen data.\n",
        "*   **Initialize XGBoost Model**: `model_xgb = xgb.XGBClassifier(eval_metric='logloss', random_state=42)` creates an instance of the XGBoost classifier. `eval_metric='logloss'` specifies the evaluation metric during training, and `random_state` ensures reproducibility.\n",
        "*   **Train Model**: `model_xgb.fit(X_train, y_train)` trains the XGBoost model using our training features and target.\n",
        "*   **Make Predictions**: `y_pred_xgb = model_xgb.predict(X_test)` uses the trained model to make predictions on the test set.\n",
        "*   **Evaluate Performance**: Finally, `accuracy_score(y_test, y_pred_xgb)` calculates the overall accuracy, and `classification_report(y_test, y_pred_xgb)` provides a detailed report including precision, recall, and f1-score for each class (stock up or stock down)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c9a7e9b1",
        "outputId": "662b735e-66b8-4573-b7d0-517b46bc2b63"
      },
      "source": [
        "pip install yfinance nltk xgboost pandas_ta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.4.71b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.1)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.28.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Collecting numba==0.61.2 (from pandas_ta)\n",
            "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting numpy>=1.16.5 (from yfinance)\n",
            "  Downloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pandas>=1.3.0 (from yfinance)\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->pandas_ta)\n",
            "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting numpy>=1.16.5 (from yfinance)\n",
            "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Downloading pandas_ta-0.4.71b0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.3/240.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, llvmlite, pandas, numba, pandas_ta\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llvmlite-0.44.0 numba-0.61.2 numpy-2.2.6 pandas-2.3.3 pandas_ta-0.4.71b0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              },
              "id": "448a0bcf2b954f0c953b058140e01cea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6541e3ca",
        "outputId": "e338b3f0-f358-473b-d478-e0210e9d4371"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "import pandas_ta as ta\n",
        "import xgboost as xgb\n",
        "\n",
        "# 1. Setup & Data Loading\n",
        "# Ensure you have the lexicon downloaded\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Download S&P 500 data (for the target variable)\n",
        "stock_df = yf.download(\"^GSPC\", start=\"2020-01-01\", end=\"2024-01-01\")\n",
        "stock_df = stock_df.reset_index()\n",
        "\n",
        "# Flatten column MultiIndex if it exists (common with yfinance output for single or multiple tickers)\n",
        "if isinstance(stock_df.columns, pd.MultiIndex):\n",
        "    new_columns = []\n",
        "    for col_tuple in stock_df.columns:\n",
        "        if col_tuple[0] == 'Date':\n",
        "            new_columns.append('Date') # Ensure 'Date' column is named correctly\n",
        "        elif col_tuple[1] == '': # Handle cases where reset_index() might create ('Date', '')\n",
        "            new_columns.append(col_tuple[0]) # This would be 'Date'\n",
        "        else:\n",
        "            # For other columns like ('Open', '^GSPC'), we want 'Open'\n",
        "            new_columns.append(col_tuple[0]) # Take the first level for stock metrics (e.g., 'Open', 'High', 'Close')\n",
        "    stock_df.columns = new_columns\n",
        "\n",
        "# Sample news data (In your project, load the Kaggle CSV here)\n",
        "# news_df = pd.read_csv('financial_news.csv')\n",
        "# For demonstration, we'll create dummy news aligned with stock dates\n",
        "headlines_pattern = [\n",
        "    \"Economy shows strong growth\",\n",
        "    \"Tech stocks crash over interest rates\",\n",
        "    \"Market remains stable despite inflation\",\n",
        "    \"Fed hints at rate cuts next month\"\n",
        "]\n",
        "num_stock_dates = len(stock_df)\n",
        "# Repeat the pattern enough times to cover all stock dates, then slice to the exact length\n",
        "repeated_headlines = (headlines_pattern * (num_stock_dates // len(headlines_pattern) + 1))[:num_stock_dates]\n",
        "\n",
        "news_data = {\n",
        "    'Date': stock_df['Date'],\n",
        "    'Headline': repeated_headlines\n",
        "}\n",
        "news_df = pd.DataFrame(news_data)\n",
        "\n",
        "# 2. Sentiment Analysis (NLP)\n",
        "def get_sentiment(text):\n",
        "    return sia.polarity_scores(text)['compound']\n",
        "\n",
        "news_df['Sentiment_Score'] = news_df['Headline'].apply(get_sentiment)\n",
        "\n",
        "# 3. Add Technical Indicators\n",
        "stock_df['SMA_5'] = stock_df['Close'].rolling(window=5).mean()\n",
        "stock_df['SMA_10'] = stock_df['Close'].rolling(window=10).mean()\n",
        "stock_df['SMA_20'] = stock_df['Close'].rolling(window=20).mean()\n",
        "\n",
        "stock_df['EMA_5'] = stock_df['Close'].ewm(span=5, adjust=False).mean()\n",
        "stock_df['EMA_10'] = stock_df['Close'].ewm(span=10, adjust=False).mean()\n",
        "stock_df['EMA_20'] = stock_df['Close'].ewm(span=20, adjust=False).mean()\n",
        "\n",
        "stock_df['RSI'] = ta.rsi(stock_df['Close'], length=14)\n",
        "\n",
        "macd = ta.macd(stock_df['Close'], fast=12, slow=26, signal=9)\n",
        "stock_df['MACD'] = macd['MACD_12_26_9']\n",
        "stock_df['MACD_Signal'] = macd['MACDs_12_26_9']\n",
        "\n",
        "# 4. Data Alignment (Feature Engineering)\n",
        "# We want to predict TOMORROW'S movement using TODAY'S sentiment.\n",
        "stock_df['Price_Diff'] = stock_df['Close'].diff()\n",
        "stock_df['Target'] = (stock_df['Price_Diff'].shift(-1) > 0).astype(int) # 1 if Up, 0 if Down\n",
        "\n",
        "# Merge news sentiment with stock data\n",
        "final_df = pd.merge(stock_df, news_df, on='Date')\n",
        "\n",
        "# Handle NaN values introduced by indicator calculations and merge\n",
        "final_df = final_df.dropna() # Remove rows without targets (last day) or initial NaNs from indicators\n",
        "\n",
        "# 5. Model Training with XGBoost\n",
        "X = final_df[['Sentiment_Score', 'Open', 'High', 'Low', 'Volume',\n",
        "              'SMA_5', 'SMA_10', 'SMA_20', 'EMA_5', 'EMA_10', 'EMA_20',\n",
        "              'RSI', 'MACD', 'MACD_Signal']]\n",
        "y = final_df['Target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_xgb = xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "model_xgb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xgb = model_xgb.predict(X_test)\n",
        "\n",
        "print(f\"XGBoost Model Accuracy: {accuracy_score(y_test, y_pred_xgb):.2%}\")\n",
        "print(\"\\nXGBoost Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "/tmp/ipython-input-1190900046.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_df = yf.download(\"^GSPC\", start=\"2020-01-01\", end=\"2024-01-01\")\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Accuracy: 45.13%\n",
            "\n",
            "XGBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.41      0.42        92\n",
            "           1       0.48      0.49      0.48       103\n",
            "\n",
            "    accuracy                           0.45       195\n",
            "   macro avg       0.45      0.45      0.45       195\n",
            "weighted avg       0.45      0.45      0.45       195\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
